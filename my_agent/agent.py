import re
from typing import AsyncGenerator
from typing_extensions import override

from google.adk.agents import BaseAgent, LlmAgent
from google.adk.agents.invocation_context import InvocationContext
from google.adk.events import Event
from google.genai import types

# Tool
def get_current_time(city: str) -> dict:
    """Retorna a hora atual em uma cidade espec√≠fica."""
    return {"status": "success", "city": city, "time": "10:30 AM"}


# Cria o LlmAgent interno
internal_llm = LlmAgent(
    name="internal_llm",
    model="gemini-2.5-flash",
    description="Agente interno para processamento",
    instruction="""Voc√™ √© um assistente brasileiro simp√°tico.

REGRAS:
1. SEMPRE pense e responda em PORTUGU√äS DO BRASIL
2. NUNCA use ingl√™s

Use a ferramenta 'get_current_time' quando perguntarem as horas.

Formato OBRIGAT√ìRIO da resposta:
PENSAMENTO: [seu racioc√≠nio detalhado em portugu√™s]
RESPOSTA: [resposta amig√°vel para o usu√°rio]
""",
    tools=[get_current_time],
)


class ThinkingAgent(BaseAgent):
    """
    Agente customizado que separa o pensamento da resposta em eventos distintos.
    """
    
    @override
    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:
        """Executa o agente e separa pensamento da resposta em eventos distintos."""
        
        full_response = ""
        
        # Executa o LLM agent interno
        async for event in internal_llm.run_async(ctx):
            # OCULTA: N√£o faz yield de function calls (tool chamada)
            if event.get_function_calls():
                continue  # ‚Üê Mudou de "yield event" para "continue"
            
            # OCULTA: N√£o faz yield de function responses (tool resultado)
            if event.get_function_responses():
                continue  # ‚Üê Mudou de "yield event" para "continue"
            
            # Acumula texto da resposta
            if event.content and event.content.parts:
                for part in event.content.parts:
                    if part.text:
                        full_response = part.text
        
        # Processa a resposta final
        if full_response:
            pensamento = ""
            resposta = full_response
            
            match_pensamento = re.search(
                r'PENSAMENTO[:\s]*(.+?)(?=RESPOSTA[:\s]|$)', 
                full_response, 
                re.DOTALL | re.IGNORECASE
            )
            match_resposta = re.search(
                r'RESPOSTA[:\s]*(.+?)$', 
                full_response, 
                re.DOTALL | re.IGNORECASE
            )
            
            if match_pensamento:
                pensamento = match_pensamento.group(1).strip()
            
            if match_resposta:
                resposta = match_resposta.group(1).strip()
            
            # Evento 1: Pensamento
            if pensamento:
                yield Event(
                    author=self.name,
                    invocation_id=ctx.invocation_id,
                    content=types.Content(
                        role="model",
                        parts=[types.Part(text=f"üí≠ **Pensamento**\n\n{pensamento}")]
                    )
                )
            
            # Evento 2: Resposta Final
            yield Event(
                author=self.name,
                invocation_id=ctx.invocation_id,
                content=types.Content(
                    role="model",
                    parts=[types.Part(text=f"ü§ñ {resposta}")]
                )
            )


# Exporta o agente como root_agent
root_agent = ThinkingAgent(
    name="thinking_agent",
    description="Agente que mostra o pensamento separado da resposta",
    sub_agents=[internal_llm],
)